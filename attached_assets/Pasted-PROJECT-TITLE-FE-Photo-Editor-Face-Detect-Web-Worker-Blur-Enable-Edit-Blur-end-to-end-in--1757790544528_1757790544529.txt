PROJECT TITLE
FE: Photo Editor (Face‑Detect + Web‑Worker Blur) — Enable “Edit & Blur” end‑to‑end in Photos tab using the existing Photo API (masks + process). No backend changes.

SCOPE RULES (IMPORTANT)

Do NOT create or modify backend routes.

Use the existing endpoints (masks/set & process).

Face‑detection runs client‑side with @vladmandic/face-api.

Heavy blur rendering runs in a Web Worker for smooth UI.

Fallback gracefully if face models are not present (manual tools still work).

Stack & Conventions

Next.js 14+ App Router, TypeScript, Tailwind CSS

Image/AI libs: @vladmandic/face-api (lazy‑load models), Canvas

Worker: Web Worker (or OffscreenCanvas if supported)

Accessibility: keyboard shortcuts + focusable controls

Auth: reuse authHeaders and endpointPaths you already set

Endpoints (centralized)

Use/extend existing config/endpointPaths.ts (names may already exist):

export const PhotoAPI = {
  listPhotos: (orderId: string) => `/api/orders/${orderId}/photos`,
  updatePhoto: (orderId: string, photoId: string) => `/api/orders/${orderId}/photos/${photoId}`,
  setMasks:    (orderId: string, photoId: string) => `/api/orders/${orderId}/photos/${photoId}/masks`,
  processBlur: (orderId: string, photoId: string) => `/api/orders/${orderId}/photos/${photoId}/process`,
  qcSummary:   (orderId: string) => `/api/orders/${orderId}/photos/qc`,
};


Place face‑api model paths in config/face.ts:

export const FACE_MODELS_BASE = '/models/faceapi'; // put files in /public/models/faceapi
export const FACE_MODEL_SET: 'tiny' | 'ssd' = 'tiny'; // allow switching

Types (align with your backend)

If not present, ensure types/photos.ts includes (or extend your existing):

export interface MaskRect { x:number; y:number; w:number; h:number; radius?: number }
export interface MaskBrushStroke { points: Array<{x:number;y:number}>, radius: number, strength: number }
export interface AutoDetection { type:'face'; x:number; y:number; w:number; h:number; accepted: boolean }

export interface PhotoMeta {
  id: string;
  orderId: string;
  displayPath: string;
  thumbPath: string;
  originalPath: string;
  processing?: { blurredPath?: string; lastProcessedAt?: string };
  masks?: { rects: MaskRect[]; brush: MaskBrushStroke[]; autoDetections?: AutoDetection[] };
  // … other fields as you already have
}

New Components & Files
1) PhotoEditorModal (the UI)

components/photos/PhotoEditorModal.tsx

Opens from PhotoTile → now enabled (no longer “coming soon”).

Canvas viewer with zoom/pan (pinch on mobile, wheel+Ctrl on desktop).

Toolbars:

Select/Move

Box Blur (create/move/resize rectangles; adjustable corner radius)

Brush Blur (radius & strength sliders; paint strokes)

Detections panel: list of faces with toggles (Accept/Reject); “Accept All / Clear All”

Before/After toggle

Undo/Redo

Save (persists masks + triggers server processing), Cancel

State: Maintain working masks (rects, brush, autoDetections) separate from persisted.

Performance: Preview blur via worker (see #2) so dragging is smooth.

2) Blur Worker (non‑blocking processing)

components/photos/blurWorker.ts

Messages:

INIT (feature detect OffscreenCanvas)

PREVIEW { imageBitmapOrData, rects, brush } → returns preview blob URL

APPLY is not strictly required (server does final process), but implement PREVIEW for live view

Blur method: Stack blur / separable Gaussian (multi‑pass) with masked regions.

Use ImageBitmap in worker when available; fallback to createImageBitmap on main thread, then transfer to worker.

3) Face detection loader

lib/face/loader.ts

Lazy‑load @vladmandic/face-api models from /public/models/faceapi/ based on FACE_MODEL_SET:

tiny face detector: tiny_face_detector_model-weights_manifest.json etc.

ssd mobilenet v1 if you choose ssd

Export detectFaces(imgHTMLCanvasOrTensor): Promise<AutoDetection[]>

If models missing or load fails → resolve with [] and set a banner flag so UI shows “Auto‑detect unavailable; use manual blur tools.”

4) API client glue

lib/photoEditorApi.ts

saveMasks(orderId, photoId, masks) → POST setMasks

processBlur(orderId, photoId) → POST processBlur

Returns updated PhotoMeta with processing.blurredPath if server writes it.

5) Wire into Photos tab

Enable Edit & Blur in PhotoTile:

Open PhotoEditorModal with the selected photo

On Save:

saveMasks(...)

processBlur(...)

Refresh photo list (mutate() from your usePhotos hook)

Refresh QC (usePhotosQc → refresh())

Add a small badge on tiles with unreviewed detections (autoDetections exists with any accepted=false).

Detection & Editing Flow

Open Modal → load the displayPath image (or processing.blurredPath for after view).

Detect faces (lazy): show spinner “Scanning for faces…”; on success, paint proposal boxes.

User can Accept/Reject proposal boxes; add Box rectangles; paint Brush strokes.

Worker renders preview progressively (on change) to keep UX responsive.

Save: persist masks, call process endpoint; show toast “Processing…done”.

Close modal; update tile (thumb may stay; show “blurred” indicator if processing.blurredPath exists).

Accessibility & Shortcuts

Keyboard:

V = Select/Move

B = Box

R = Brush

[ / ] = Brush radius –

Ctrl/Cmd+Z = Undo, Ctrl/Cmd+Shift+Z = Redo

\ = Before/After toggle

All buttons have aria-label and focus outlines.

UI Details

Before/After overlays the processed preview atop original via opacity toggle.

Detections panel lists boxes with eye icon (show/hide), checkbox (include in masks), delete.

Brush draws freehand; show a cursor circle for radius.

Undo/Redo is per‑session; masks persisted only on Save.

Acceptance Criteria (demo checklist)

 “Edit & Blur” opens a fully working editor modal on a photo tile.

 Face detection proposes blur boxes; user can accept/reject; if models missing, a banner appears and manual tools still work.

 Box & Brush tools work smoothly; preview blur renders via Web Worker without jank.

 Save persists masks and triggers server processing; reopening the editor shows the same masks (non‑destructive).

 Photo tile reflects blurred state (indicator) when processing.blurredPath is present.

 QC updates: if all detections are reviewed and required photos exist, Photos QC can turn Green.

 Keyboard shortcuts & a11y labels are present; mobile pinch‑zoom works.

Manual Test Script (60‑second)

Open /orders/123 → Photos tab → click a tile with a person → Edit & Blur.

Wait for “Scanning faces…” → boxes appear → Accept All → Save → toast “Processing…done”; tile shows blurred indicator.

Reopen editor → Before/After toggles correctly; boxes persist.

Pick another image → draw a Box over a license plate, paint a Brush on a picture frame → Save → reopen to confirm persistence.

Break models path (rename folder) → open editor → see banner “Auto‑detect unavailable”; manual tools still work.

Check QC badge → unresolved detections count decreases after Save; sign‑off allowed if requirements met.

Libraries to Add
npm i @vladmandic/face-api


Place face‑api model files under /public/models/faceapi/ (TinyFace or SSD). Lazy‑load with try/catch; fall back gracefully.

Deliver exactly this slice, integrated into your existing Photos tab (no new backend), so the editor is production‑ready and QC can fully leverage automated detection + worker‑based blur.

After this slice (coming up next)

Market Conditions + Time Adjustments (MCR): compute trend %/month from your market polygon + sales/listings.

3‑Engine Adjustments: Regression, Depreciated Cost, Paired Sales with blend sliders per attribute.

Final Reconciliation “gut check”: approaches + AVM + tax + last sale deltas with narrative prompts.

If you want, say “MCR” or “3‑Engines” and I’ll paste a ready‑to‑run prompt for the next sprint.